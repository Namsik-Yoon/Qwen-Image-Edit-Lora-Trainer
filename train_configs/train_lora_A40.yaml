pretrained_model_name_or_path: Qwen/Qwen-Image-Edit
data_config:
  train_batch_size: 1
  num_workers: 16
  img_size: 1024
  caption_dropout_rate: 0.1
  img_dir: /workspace/Qwen-Image-Edit-Lora-Trainer/datasets/images
  mask_dir: /workspace/Qwen-Image-Edit-Lora-Trainer/datasets/masks
  prompt_dir: /workspace/Qwen-Image-Edit-Lora-Trainer/datasets/prompts
  random_ratio: false # support multi crop preprocessing
  caption_type: txt
report_to: tensorboard
train_batch_size: 1
output_dir: /workspace/Qwen-Image-Edit-Lora-Trainer/outputs
max_train_steps: 5000
learning_rate: 2e-4
lr_scheduler: constant
lr_warmup_steps: 10
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 1e-8
max_grad_norm: 1.0
logging_dir: logs
mixed_precision: "bf16"
checkpointing_steps: 100
checkpoints_total_limit: 50
tracker_project_name: lora_edit
resume_from_checkpoint: latest
gradient_accumulation_steps: 1
rank: 16
precompute_text_embeddings: true
precompute_image_embeddings: true
quantize: true
adam8bit: true
save_cache_on_disk: true
quantize_last_k_blocks: 8 
mask_fg_boost: 2.0           # Edit area (green) weight multiplier
mask_bg_scale: 1.0           # Background weight multiplier
lambda_identity_bg: 0.0      # Background identity regularization strength (0 to turn off)

# Inference and visualization settings
inference_config:
  enable_inference: false  # Whether to run inference (modified to inference_edit.py style)
  test_images: []  # Test image paths (if empty, randomly select 3 from control folder)
  num_inference_steps: 50
  cfg_scale: 5.0  # Same setting as inference_edit.py
  seed: 42

